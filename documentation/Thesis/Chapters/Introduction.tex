\chapter{Introduction}
\label{sec:introduction}

Inverse Problems aim to estimate an original signal that went through a system, 
based on potentially noisy output signal observations.
They are widely used throughout different science directions, such as Machine Learning (ML),
Signal Processing, Computer Vision, Natural Language Processing and others.
ML is one tool to model and solve such inverse problems.


\bigskip

In recent years, graphs got a lot of attention in ML and Graph Machine Learning is one of the most promising research areas.
Graphs are a well suited data structure, simple but with high expressiveness. 
Especially data for which single data points tend to have a relation to other data points, graphs with its nodes and vertices are the perfect tool
to capture these relationships. 
Data is in a graph structure already, like social networks, or they can be artificially constructed for arbitrary datasets.
Besides, for some scenarios, ordinary ML algorithms fail, but Graph ML approaches have great success, e.g. dimensionality reduction for high-dimensional data.


\bigskip

Cryo-Electron Microscopy (cryo-EM) is a molecular imaging method and gained a lot of attention in recent years. 
Molecules are frozen and imaged through an electron microscope.
Due to ground-breaking improvements regarding hardware and data processing, the field of research
has highly improved. In 2017, pioneers in the field of cryo-EM got the 
Nobel Prize in Chemistry\footnote{https://www.nobelprize.org/prizes/chemistry/2017/press-release/}.
Today, using cryo-EM, molecular structures can be observed with near-atomic resolution.
The big challenge with cryo-EM is enormous noise and unknown observation angles.

Computed tomography (CT) is a similar to cryo-EM, but reconstruction is slightly easier
as the problem is in 2D and observation angles are known.
The overall goal of this Thesis is to introduce an algorithm that works with CT, but 
can conceptually be extended to work in 3D, thus for cryo-EM. 
Additionally, the focus is on the high noise domain, as current available reconstruction algorithms
start to fail when dealing with too much noise.  

\clearpage

As a result of this Thesis, a Graph Neural Network (GNN) architecture is proposed, which is called \textit{GAT-Denoiser}.
GAT-Denoiser aims to denoise noisy observations from CT to improve overall reconstruction quality.
In the GNN architecture, convolution and Graph Attention Network (GAT) is used to denoise observations.
In addition, an end-to-end learning approach with U-Net is used to further improve reconstruction quality, 
where a pre-trained U-Net is jointly optimized further during GAT-Denoiser training.

GAT-Denoiser was evaluated on the LoDoPaB-CT dataset~\cite{lodopab-dataset}.
I could show that all three components contribute to learning the best GAT-Denoiser model.
Moreover, GAT-Denoiser outperformed BM3D~\cite{bm3d} as well as U-Net~\cite{unet-tomography},
where observation signal-to-noise-ration (SNR) is between 0 dB and -15 dB.
Compared to best performing baseline BM3D, GAT-Denoiser could improve reconstruction SNR 
by 150\%, for SNR 0dB , -5 dB, -10 dB and -15 dB respectively.
The best GAT-Denoiser could be established, when first, GAT-Denoiser is trained with a fixed U-Net model.
After some learning, in a second step, GAT-Denoiser and U-Net have been trained jointly.


\bigskip

The report is structured as follows: 


In Chapter~\ref{sec:imaging} \textit{\nameref{sec:imaging}}, the two molecular imaging methods
CT and cryo-EM are introduced as well as a mathematical abstraction for observation and reconstruction.
Further, Chapter~\ref{sec:graphFoundations} \textit{\nameref{sec:graphFoundations}} is dedicated to graphs, 
where graph foundations are introduced and connection from graphs to molecular imaging methods are established. 
Besides, the problem of "Graph Denoising" is defined and methods like graph construction and Graph Laplacian are introduced.
The main concept of GAT-Denoiser is described in Chapter~\ref{sec:contribution} \textit{\nameref{sec:contribution}}
and results are presented in Chapter~\ref{sec:results} \textit{\nameref{sec:results}}.
Finally, conclusion and future work are presented in Chapter~\ref{sec:Conclusion} \textit{\nameref{sec:Conclusion}}.

\chapter{Notation}

Some Math: concat operator.
SNR, \snry
Graphs: notation, edges, nodes, A, k-NN.