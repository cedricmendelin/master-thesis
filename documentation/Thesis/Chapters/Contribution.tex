\chapter{Contribution}
\label{sec:contribution}

In the following chapter, contribution during Master Thesis is presented.
As result, a GNN can be presented and it is called \textit{GAT-Denoiser}.
The idea of GAT was applied to create an observation denoiser and therefore, GAT
will be shortly explained in more detailed way.

The focus during practical part was on classical computed tomography in 2D but
can be generalized to cryo-EM and 3D. The base structure 

\section{Graph Attention Networks}

\subsection{Heads}

\subsection{Connection to molecular imaging}

\section{GAT-Denoiser}
\subsection{Architecture}
\subsection{Convolution with U-NET}
\subsection{Loss}


Motivation:
\begin{itemize}
  \item Sinogram can be reconstructed nicely with known angles.
  \item If angles are unknown, angles can be estimated by 1D manifold.
  \item K-nn parameter is crucial (add simpel example)
  \item If sinogram is noisy, k-nn is even harder
  \item What to do in high-noisy regime?
\end{itemize}

Assumption:
Circle Graph good approximation of "true" observation angles:

To check:
Train GAT-Denoiser with equally sampled points but denoise with
normal distributed points.
(No code change needed).

To check:
Traing GAT-Denoiser with normal distributed sampled points.
(Initialize different odl operators)



\begin{itemize}
  \item Angles 
  \item Importance of K-nn 
  \item Introduce GAT-Denoiser
  \item Show/illustrate - GAT Architecture
  \item Potential of Forward / Backward domain
  \item Loss L1 and L2
  \item Works with circle-graph, not with random-graph
\end{itemize}