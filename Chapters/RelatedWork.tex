
%\section{Manifold Learning}


\citet{learningToDrop} introduced PTDNET, a way of topological denoising in graphs.
It can be seen as two neural networks, where the first is called denoising network and the second is a GNN.
Firstly, in the denoising network noisy edges will be removed due to
sampling subgraphs from a learned distribution on edges. The aim is to remove 
irrelevant edges. Further, in the GNN the node representation of the denoise graph is learned.



\section{Related tomography papers}
In the last section of related work, papers which have a connection to the Master Thesis domain will be introduced.

\citet{LaplaceRandomProjections} introduces a Laplacian-based algorithm, with which 
reconstruction of a planar object from projections at random unknown directions is possible.
It can be seen as an algorithm for solving classical tomography, where the problem is extended
by the fact that projection angles are unknown. 
They could order projections of the Shepp-Logan phantom by using the Graph Laplacian 
and used this fact to successfully reconstruct the phantom, even if observations are noisy. 
The proposed algorithm is not directly applicable to the reconstruction of cryo-EM 
as projection in 3D do not have a proper ordering.

\citet{cryoEmVAE-GAN} introduced a way of estimation camera parameter (PSF) as well
as the unknown rotation in cryo-EM reconstruction problem. 
They combined a Variational Autoencoder (VAE) with a Generative Adversarial Network (GAN).
The VAE can be seen as learning a manifold to fit the observations
which was used as an input to the GAN.

Diffusion maps\cite{diffusionMaps} (DM) is a non-linear approach for calculating low-dimensional manifolds
for (high-dimensional) datasets. 
The process is based on the concept of random-walks and works as follows:
First of all, matrix $P$ is calculated which contains the probability from moving from one node to another.
Similar to the k-neighbourhood of $A$ introduced in the foundation chapter, with power of $P^t$
probabilities of reaching node $i$ in $t$ hops can be calculated. 
The diffusion distance at time $t$ can be seen as a distance measure for two nodes in the diffusion space
with added connectivity. It approximates the euclidean distance in the diffusion space and therefore 
allows to compare node embeddings regarding their euclidean distance.
With diagonalization of $P$ and selecting the first $n$ largest eigenvalues/eigenvectors the embedding can be computed.
Vector DM (VDM)\cite{vectorDiffusionMaps} generalize the concept of DM for vector fields.
Multi-Frequency Vector Diffusion Maps (MFVDM)\citet{multiDiffusionMaps} 
can be seen as an extension to Vector Diffusion Maps (VDM)\cite{vectorDiffusionMaps}, 
which works well even on highly noisy environments.
\cite{multiDiffusionMaps} was successfully used in cryo-EM setting, where it was used for denoising purpose\cite{cryoEmMutliDM}.
