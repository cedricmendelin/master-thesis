
\chapter{TODO}
\section{Foundations todo}

\subsection{cryoEm}


\begin{itemize}
    \item Graph construction with k-NN
    \item Curvature
    \item Convolution
    \item Fourier transform and Fourier frequencies
    \item SO(3), S
    \item Manifold assumption
    \item Power Iterations
    \item Non linear dimensionality reduction
\end{itemize}

Nice to have:
\begin{itemize}
    \item Hilbert Space
    \item Signal Processing    
    \item LIE Group
    \item Local PCA
    \item Curvature
    \item Graphlets
    \item Link prediction
    \item Geodesic distance
    \item Katz Index
    \item Eigenvector centrality
    \item NN forward passing
    \item NN dropout after layer
\end{itemize}

\section{Convolution}
\begin{equation}
    (f \star g)(t) := \int_{-\infty}^{\infty} f(\tau) g(t - \tau) d\tau
\end{equation}

\subsection{Eigenvector centrality}
\subsection{NN forward passing}
\begin{equation}
    H^{i + 1} = \sigma ( W^i H ^i + b^i) 
\end{equation}
%\footnote{https://towardsdatascience.com/understanding-graph-convolutional-networks-for-node-classification-a2bfdb7aba7b}
