{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86303b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3365aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "#from skimage.transform import rotate\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "#import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import torch\n",
    "from skimage.data import shepp_logan_phantom\n",
    "from skimage.transform import  rescale, radon, iradon\n",
    "from skimage.morphology import disk\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from FBB import FBBasis2D\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import rotate\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import sys\n",
    "#import plotly.graph_objects as go\n",
    "sys.path.insert(0, '..')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import rotate\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import sys\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5af72a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation3d(d3_points,phi,psi,theta):\n",
    "    r = R.from_euler('xyz', [phi, psi, theta], degrees=True)\n",
    "    return r.apply(d3_points)\n",
    "\n",
    "def inplane_distance_points(dataset,M=100):\n",
    "    print('search one')\n",
    "    N=dataset.shape[0]\n",
    "    data2d=torch.tensor(dataset,dtype=torch.float32)\n",
    "\n",
    "\n",
    "    theta=torch.arange(0,2*np.pi,2*np.pi/M)\n",
    "    rot_matrix=torch.empty(M,2,2)\n",
    "    rot_matrix[:,0,0]=torch.cos(theta)\n",
    "    rot_matrix[:,0,1]=-torch.sin(theta)\n",
    "    rot_matrix[:,1,0]=torch.sin(theta)\n",
    "    rot_matrix[:,1,1]=torch.cos(theta)\n",
    "\n",
    "    distance_matrix=torch.empty((N,N))\n",
    "    angle_matrix=torch.empty((N,N))\n",
    "    for i in tqdm(range(N)):\n",
    "        pts2dI=data2d[i,:,:]\n",
    "        pts2dI_bt=torch.broadcast_to(pts2dI,(data2d.shape[0],M,data2d.shape[1],data2d.shape[2]))\n",
    "        pts2d_rot=torch.einsum('nzp,mpq->nmzq', data2d, rot_matrix)\n",
    "        diff=torch.norm(pts2d_rot-pts2dI_bt,dim=(2,3))\n",
    "        diff,min_index=torch.min(diff,dim=1)\n",
    "        distance_matrix[i,:]=diff\n",
    "        angle_matrix[i]=theta[min_index]\n",
    "    return distance_matrix.numpy(),angle_matrix.numpy()\n",
    "\n",
    "\n",
    "def get_img(d3_points,resolution=50,xlim=[-1,1],ylim=[-1,1],theta=None,block=False):\n",
    "    [xlim_l,xlim_u]=xlim\n",
    "    [ylim_l,ylim_u]=ylim\n",
    "    devx=(xlim_u-xlim_l)/resolution\n",
    "    devy=(ylim_u-ylim_l)/resolution\n",
    "    data_2d=d3_points[:,:2]\n",
    "    if theta is not None:\n",
    "        rot_matrix=np.empty((2,2))\n",
    "        rot_matrix[0,0]=np.cos(theta)\n",
    "        rot_matrix[0,1]=-np.sin(theta)\n",
    "        rot_matrix[1,0]=np.sin(theta)\n",
    "        rot_matrix[1,1]=np.cos(theta)\n",
    "        data_2d=data_2d@rot_matrix\n",
    "    data_2d=data_2d.T\n",
    "\n",
    "\n",
    "    xcord=(data_2d[0,:]-(xlim_l))/devx\n",
    "    ycord=(data_2d[1,:]-(ylim_l))/devy\n",
    "\n",
    "\n",
    "    xcord[xcord>=resolution]=resolution-1\n",
    "    xcord[ycord>=resolution]=resolution-1\n",
    "    xcord[xcord<0]=0\n",
    "    ycord[ycord<0]=0\n",
    "\n",
    "\n",
    "    xcord=torch.tensor(xcord,dtype=torch.long)\n",
    "    ycord=torch.tensor(ycord,dtype=torch.long)\n",
    "    z=torch.ones_like(xcord,dtype=torch.int)\n",
    "    img=torch.zeros((resolution,resolution),dtype=torch.int)\n",
    "    img.index_put_((xcord, ycord), z, accumulate=True)\n",
    "    img=img.numpy()\n",
    "    if block:\n",
    "        img[img>0]=1\n",
    "    return img\n",
    "\n",
    "def get_img_3d(d3_points,resolution=50,xlim=[-1,1],ylim=[-1,1],zlim=[-1,1],theta=None,block=False):\n",
    "    [xlim_l,xlim_u]=xlim\n",
    "    [ylim_l,ylim_u]=ylim\n",
    "    [zlim_l,zlim_u]=zlim\n",
    "    devx=(xlim_u-xlim_l)/resolution\n",
    "    devy=(ylim_u-ylim_l)/resolution\n",
    "    devz=(ylim_u-ylim_l)/resolution\n",
    "    data_3d=d3_points.T\n",
    "\n",
    "\n",
    "\n",
    "    xcord=(data_3d[0,:]-(xlim_l))/devx\n",
    "    ycord=(data_3d[1,:]-(ylim_l))/devy\n",
    "    zcord=(data_3d[2,:]-(zlim_l))/devz\n",
    "\n",
    "\n",
    "\n",
    "    xcord[xcord>=resolution]=resolution-1\n",
    "    xcord[ycord>=resolution]=resolution-1\n",
    "    zcord[zcord>=resolution]=resolution-1\n",
    "    xcord[xcord<0]=0\n",
    "    ycord[ycord<0]=0\n",
    "    zcord[zcord<0]=0\n",
    "\n",
    "\n",
    "    xcord=torch.tensor(xcord,dtype=torch.long)\n",
    "    ycord=torch.tensor(ycord,dtype=torch.long)\n",
    "    zcord=torch.tensor(zcord,dtype=torch.long)\n",
    "    z=torch.ones_like(xcord,dtype=torch.int)\n",
    "    img=torch.zeros((resolution,resolution,resolution),dtype=torch.int)\n",
    "    img.index_put_((xcord, ycord,zcord), z, accumulate=True)\n",
    "    img=img.numpy()\n",
    "    if block:\n",
    "        img[img>0]=1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "784b6a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts=np.load(\"maps/bunny.npy\")\n",
    "pts=pts[np.random.permutation(pts.shape[0]),:]\n",
    "\n",
    "resolution = 50\n",
    "\n",
    "pts[:,0]=pts[:,0]-(pts[:,0].max()+pts[:,0].min())/2\n",
    "pts[:,1]=pts[:,1]-(pts[:,1].max()+pts[:,1].min())/2\n",
    "pts[:,2]=pts[:,2]-(pts[:,2].max()+pts[:,2].min())/2\n",
    "pts_max=np.linalg.norm(pts,axis=1).max()\n",
    "pts=pts/pts_max\n",
    "\n",
    "V=get_img_3d(pts,resolution=resolution,block=True)\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils.Vedo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e6af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "ax.voxels(V)\n",
    "ax.view_init(30, 150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6ee9e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0.029984\n"
     ]
    }
   ],
   "source": [
    "print(V.max())\n",
    "print(V.min())\n",
    "print(V.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3077fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedWindow(verbose=True): could not load ipyvtklink try:\n",
      "> pip install ipyvtklink\n",
      "2022-01-27 16:59:05,497 ERROR Corresponding complex type is not defined for int32.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Corresponding complex type is not defined for int32.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ccda17cdae08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0maspire_vol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoisy_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreconstruct_result_cheng\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_adj_mat_nx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\master-thesis\\src\\utils\\Data.py\u001b[0m in \u001b[0;36mreconstruct_result_cheng\u001b[1;34m(V, n, img_size, snr, k)\u001b[0m\n\u001b[0;32m    100\u001b[0m      \u001b[1;31m# create aspire volume and downsample to image size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0maspire_vol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVolume\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0maspire_vol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maspire_vol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;31m# return values:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\master-thesis-3.6\\lib\\site-packages\\aspire\\volume\\__init__.py\u001b[0m in \u001b[0;36mdownsample\u001b[1;34m(self, szout, mask)\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mszout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mszout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mVolume\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maspire\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mszout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\master-thesis-3.6\\lib\\site-packages\\aspire\\image\\preprocess.py\u001b[0m in \u001b[0;36mdownsample\u001b[1;34m(insamples, szout, mask)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             insamples_shifted = fft.fftshift(\n\u001b[1;32m--> 172\u001b[1;33m                 \u001b[0mfft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfftn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minsamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m             )\n\u001b[0;32m    174\u001b[0m             \u001b[0minsamples_fft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrop_pad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minsamples_shifted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_out\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\master-thesis-3.6\\lib\\site-packages\\aspire\\numeric\\pyfftw_fft.py\u001b[0m in \u001b[0;36mfftn\u001b[1;34m(self, a, axes, workers)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mmutex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mcomp_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomplex_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0ma_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyfftw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_aligned\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomp_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\master-thesis-3.6\\lib\\site-packages\\aspire\\utils\\types.py\u001b[0m in \u001b[0;36mcomplex_type\u001b[1;34m(realtype)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Corresponding complex type is not defined for {realtype}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcomplextype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Corresponding complex type is not defined for int32."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "\n",
    "from aspire.volume import Volume\n",
    "\n",
    "from utils.Data import *\n",
    "from utils.AspireHelpers import *\n",
    "from utils.Plotting import *\n",
    "import time\n",
    "import mrcfile\n",
    "\n",
    "from utils.Plotting import plot_voxels\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "aspire_vol = Volume(V)\n",
    "\n",
    "\n",
    "img_size = 100  # image size in square\n",
    "n_img = 1000  # number of images\n",
    "snr = 10\n",
    "K = 10\n",
    "\n",
    "aspire_vol, sim, clean_graph, noisy_graph = reconstruct_result_cheng(V, n_img, img_size, snr, K)\n",
    "\n",
    "A = create_adj_mat_nx(clean_graph.classes)\n",
    "\n",
    "embedding = calc_graph_laplacian(A, numberOfEvecs=3)\n",
    "embedding_normalized = normalize_min_max(embedding)\n",
    "\n",
    "plot_3dscatter(embedding_normalized[:,0], embedding_normalized[:,1], embedding_normalized[:,2])\n",
    "\n",
    "embedding_normalized = align_3d_embedding_to_shpere(embedding_normalized)\n",
    "\n",
    "plot_3dscatter(embedding_normalized[:,0], embedding_normalized[:,1], embedding_normalized[:,2])\n",
    "\n",
    "rots = calc_rotation_from_points_on_sphere(embedding_normalized)\n",
    "\n",
    "clean_images = sim.images(0, n_img).asnumpy()\n",
    "rec_calculated_rots = reconstruction_naive(clean_images, n_img, img_size, rots)\n",
    "#rec_given_rots = reconstruction_naive(clean_images, n_img, img_size, sim.angles)\n",
    "\n",
    "\n",
    "voxelSaveAsMap(rec_calculated_rots, 'rec_calculated_rots_2.map')\n",
    "#voxelSaveAsMap(rec_calculated_rots, 'rec_given_rots.map')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
